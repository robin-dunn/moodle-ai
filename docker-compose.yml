---
services:

  redis:
    image: redis:alpine
    restart: unless-stopped

  postgres:
    image: postgres:alpine
    restart: unless-stopped
    environment:
      - POSTGRES_PASSWORD=moodle
      - POSTGRES_USER=moodle
      - POSTGRES_DB=moodle
    volumes:
      - postgres:/var/lib/postgresql/data

  moodle:
    image: erseco/alpine-moodle
    build:
      context: .
      args:
        # To use a specific Moodle version, set MOODLE_VERSION to git release tag.
        # You can find the list of available tags at:
        # https://api.github.com/repos/moodle/moodle/tags
        #
        # Example:
        # MOODLE_VERSION: v4.5.3
        # MOODLE_VERSION: v5.0.1
        MOODLE_VERSION: main
    restart: unless-stopped
    environment:
      LANG: en_US.UTF-8
      LANGUAGE: en_US:en
      SITE_URL: http://localhost
      DB_TYPE: pgsql
      DB_HOST: postgres
      DB_PORT: 5432
      DB_NAME: moodle
      DB_USER: moodle
      DB_PASS: moodle
      DB_PREFIX: mdl_
      REDIS_HOST: redis
      REVERSEPROXY: false
      SSLPROXY: false
      MOODLE_EMAIL: user@example.com
      MOODLE_LANGUAGE: en
      MOODLE_SITENAME: New-Site
      MOODLE_USERNAME: moodleuser
      MOODLE_PASSWORD: PLEASE_CHANGEME
      SMTP_HOST: smtp.gmail.com
      SMTP_PORT: 587
      SMTP_USER: your_email@gmail.com
      SMTP_PASSWORD: your_password
      SMTP_PROTOCOL: tls
      MOODLE_MAIL_NOREPLY_ADDRESS: noreply@localhost
      MOODLE_MAIL_PREFIX: "[moodle]"
      PRE_CONFIGURE_COMMANDS: |
        echo 'This is a pre-configure command'
      POST_CONFIGURE_COMMANDS: |
        if [ -d "/var/www/html/local/showmyai" ]; then
          chown -R nobody:nobody /var/www/html/local/showmyai
          chmod -R 755 /var/www/html/local/showmyai
          php /var/www/html/admin/cli/upgrade.php --non-interactive
        fi
    ports:
      - 80:8080
    volumes:
      - ./plugins/showmyai:/var/www/html/local/showmyai 
    depends_on:
      - postgres
      - redis

  ollama:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama:/root/.ollama
    ports:
      - 11434:11434

  showmyai:
    build:
      context: ./showmyai-app
      dockerfile: Dockerfile
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=3000
      - AI_PROVIDER=${AI_PROVIDER:-ollama}
      - OLLAMA_BASE_URL=http://ollama:11434
      - OLLAMA_MODEL=${OLLAMA_MODEL:-phi3}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GEMINI_MODEL=${GEMINI_MODEL:-gemini-1.5-flash-latest}
      - GEMINI_TEMPERATURE=${GEMINI_TEMPERATURE:-0.7}
      - GEMINI_MAX_TOKENS=${GEMINI_MAX_TOKENS:-1000}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL=${OPENAI_MODEL:-gpt-3.5-turbo}
      - OPENAI_TEMPERATURE=${OPENAI_TEMPERATURE:-0.7}
      - OPENAI_MAX_TOKENS=${OPENAI_MAX_TOKENS:-1000}
    ports:
      - 3000:3000
    depends_on:
      - moodle
      - ollama

volumes:
  postgres: null
  moodledata: null
  moodlehtml: null
  ollama: null
